---
title: "ADP Practice 4"
author: "Ku, Bonseong"
date: '2020 12 9 '
output: html_document
---

## 데이터, 패키지 로드
```{r, warning=FALSE, message=FALSE}
library(rpart)
library(rpart.plot)
library(randomForest)
library(e1071)
library(ROCR)
library(caret)
library(lmtest)
library(tm)
library(rJava)
library(KoNLP)
library(wordcloud)
library(plyr)
library(stringr)

AUS<-read.csv('weatherAUS.csv')
bike<-read.csv('bike_marketing.csv')
instagram_tour<-readLines("instagram_태교여행.txt")
set.seed(6789)
```

## 정형 데이터마이닝
### 데이터 전처리, 스플릿
```{r}
summary(AUS)
```
```{r}
AUS_1<-AUS[,-c(8,14,15,16,17)]
AUS_1$Date<-as.Date(AUS_1$Date)
AUS_1<-na.omit(AUS_1) # 결측치 제거
sum(is.na(AUS_1))
```
```{r}
AUS_1<-AUS_1[0:1000,] # 데이터 1000개만 이용, 원래는 fulldata 해야하지만 연습이니까...

idx<-sample(1:nrow(AUS_1),size=nrow(AUS_1)*0.7,replace=FALSE)
AUS_train<-AUS_1[idx,]
AUS_test<-AUS_1[-idx,]
cat(nrow(AUS_train),nrow(AUS_test))
```


### 의사결정나무
#### 모형적합
```{r}
tree.fit<-rpart(RainTomorrow~., data=AUS_train, method="class", control = rpart.control(maxdepth=5, minsplit=15))
tree.fit
```
```{r}
prp(tree.fit,type=4,extra = 2)
```
```{r}
pred_tree<-predict(tree.fit,AUS_test[,-length(AUS_test)],type='prob')
pred_tree2<-predict(tree.fit,AUS_test[,-length(AUS_test)],type='class')

write.csv(cbind(pred_tree,pred_tree2),'decisiontree.csv')
```
#### 모형평가
```{r}
confusionMatrix(data=pred_tree2,reference=AUS_test[,16], positive="Yes")
```
```{r}
pred.dt.roc<-prediction(as.numeric(pred_tree2),as.numeric(AUS_test[,16]))
plot(performance(pred.dt.roc,"tpr","fpr"))
abline(a=0,b=1,lty=2,col="black")
```

```{r}
performance(pred.dt.roc,"auc")@y.values
```
### 랜덤포레스트
```{r}
rf.fit<-randomForest(RainTomorrow~., data=AUS_train)
rf.fit
```
```{r}
pred_rf<-predict(rf.fit, AUS_test[,-16], type='prob')
pred_rf2<-predict(rf.fit, AUS_test[,-16], type='class')

write.csv(cbind(pred_rf,pred_rf2), 'randomforest.csv')
```
#### 모형평가
```{r}
confusionMatrix(data=pred_rf2,reference=AUS_test[,16], positive="Yes")
```
```{r}
pred.rf.roc<-prediction(as.numeric(pred_rf2),as.numeric(AUS_test[,16]))
plot(performance(pred.rf.roc,"tpr","fpr"))
abline(a=0,b=1,lty=2,col="black")
```
```{r}
performance(pred.rf.roc,"auc")@y.values
```

### 나이브베이즈
```{r}
nv.fit<-naiveBayes(RainTomorrow~., data=AUS_train)
```
```{r}
pred_nv<-predict(nv.fit, AUS_test[,-16], type='raw')
pred_nv2<-predict(nv.fit, AUS_test[,-16], type='class')
write.csv(cbind(pred_nv,pred_nv2), 'naivebayes.csv')
```
#### 모형평가
```{r}
confusionMatrix(data=pred_nv2,reference=AUS_test[,16], positive="Yes")
```
```{r}
pred.nv.roc<-prediction(as.numeric(pred_nv2),as.numeric(AUS_test[,16]))
plot(performance(pred.nv.roc,"tpr","fpr"))
abline(a=0,b=1,lty=2,col="black")
```
```{r}
performance(pred.nv.roc,"auc")@y.values
```
- 의사결정나무는 설명력이 다소 부족했다.
- 랜덤포레스트는 정확돠와 AUC 부분에 있어 가장 높은 수치를 기록했다.
- 나이브 베이즈 결과, 정확도가 83%로 높은 수치이지만, 랜덤포레스트에 비해 낮게 나왔다.
- 데이터의 특성에 따라 정확도를 제외한 특이도, 민감도 등도 함께 파악하여 해당 데이터에 가장 적절한 분석 모형을 선택해야 한다.

## 통계분석
```{r}
sum(is.na(bike)) #결측치 확인인
```
```{r}
bike$pop_density<-as.factor(bike$pop_density)
```
### 분산분석
```{r}
summary(aov(revenues~pop_density, data=bike))
```
- pop_density 별 revenues의 평균 차이가 있는지에 대한 분석이다.
- anova table을 확인한 결과, ssa의 df는 2, sst의 자유도는 169이다.
- p-value = 0.545 > 0.05 이므로 pop_density 간 revenues 의 평균이 다르다는 대립가설을 기각한다.
- 따라서 pop_density 별 revenues의 차이는 없다고 할 수 있다.

### 회귀분석
```{r}
bike_lm<-lm(revenues~google_adwords+facebook+twitter+marketing_total+employees, data=bike)
summary(bike_lm)
```
- full 모형이다. 모든 변수가 유의하다.
- 모형의 결정계수는 0.8733이며 수정된 결정계수는 0.8695이다. 이 모형은 전체 데이터의 87.33% 를 설명한다.
- F통계량에 대한 p-value는 <0.05 이므로 통계적으로 유의하다.

```{r}
formula_low<-lm(revenues~1, data=bike)
formula_high<-bike_lm

bike_lm2<-step(formula_low, scope=list(upper=formula_high), direction='forward')
summary(bike_lm2)
```
- 전진선택법에 의해 최소모형 (잔차) 부터 최대모형 (full) 까지 변수를 선택한다.
- AIC를 낮추는 방향으로 변수를 선택한다.
- 그 결과, 모든 변수를 사용하는 것이 AIC가 가장 낮게 나왔다.

### 잔차분석
#### 독립성 가정 검정
```{r}
dwtest(bike_lm2)
```
- dw값이 2.1114로 2에 근접하다.
- 따라서 독립성 가정을 만족한다고 할 수 있다.
#### 정규성 가정 검정
```{r}
shapiro.test(resid(bike_lm2))
```
- 정규성 가정을 샤피로윌크 테스트를 한 결과, p-value>0.05 이다.
- 귀무가설인 데이터가 정규성을 따른다를 채택한다. 따라서 정규성을 만족한다고 할 수 있다.

#### 등분산성 검정
```{r}
par(mfrow=c(2,2))
plot(bike_lm2)
par(mfrow=c(1,1))
```
- 1번 차트에서 그래프의 기울기가 x축과 평행하다고 보기 어렵다. 따라서 등분산성은 만족되는 것이 아닌걸로 보인다.
- 2번 차트는 점들이 주로 직선위에 있으므로 정규성을 만족한다고 볼 수 있따.
- 3번 차트는 빨간선의 기울기가 0에 가까워야 하지만, Fitted Values가 커질수록 기울기가 다소 변화하는 경향을 보이고 있다. 이렇게 빨간선의 기울기가 0에서 떨어진 점이 있따면 해당 점에서는 표준화 잔차가 큼을 의미하고, 회귀 직선이 y값을 잘 적합하지 못함을 의미한다. 또한 해당 점들은 이상치일 가능성이 있다.
- 4번 차트는 빨간 점선으로 표현되는 쿡의 거리가 0.5이상이면 빨간 점선 으로 표현되고, 점선 바깥에 있는 점들은 무시할 수 없을 정도로 예측치를 벗어난 값이다. 본 그래프에서 그러한 점들은 보이지 않으므로 회귀직선에 크게 영향을 끼치는 점들은 드물다고 볼 수 있다.
- 잔차분석 결과, 등분산성을 만족하다고 보기 어렵기 때문에, 본 모형은 활용하기 어렵다.

## 비정형 데이터 마이닝
```{r}
clean_txt<-function(txt){
  txt<-tolower(txt)             # 대, 소문자 변환
  txt<-removePunctuation(txt)   # 구두점 제거
  txt<-removeNumbers(txt)       # 숫자 제거
  txt<-stripWhitespace(txt)     # 공백제거
  
  return(txt)
}
tour_1<-clean_txt(instagram_tour)
head(tour_1)
```
```{r}
tour1<-sapply(tour_1,extractNoun)

table.cnoun<-head(sort(table(unlist(tour1)),decreasing=T),10)

barplot(table.cnoun, main="tour 데이터 빈출 명사", 
        xlab="단어",
        ylab="빈도")
```
```{r}
result<-data.frame(sort(table(unlist(tour1)),decreasing=T))

t<-wordcloud(result$Var1,result$Freq,color=brewer.pal(6,"Dark2"),min.freq=20)
```
